{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ED-RAY AUTRA PROJECT"
      ],
      "metadata": {
        "id": "LHFJ0kaTSAHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "RAY AUTRA TEAM\n",
        "NASA SPACE APP CHALLENGE 2025\n",
        "ED-RAY AUTRA PROJECT\n",
        "\n",
        "Title: Training a Tabular Data Classifier for Exoplanetology (PyTorch MLP)\n",
        "\n",
        "Objective:\n",
        "This script implements a complete pipeline for training an exoplanet classification model\n",
        "(or similar tabular data, here 'cumulative.csv').\n",
        "The model is a Multi-Layer Perceptron (MLP) built with PyTorch.\n",
        "\n",
        "Key Steps:\n",
        "1.  **Data Loading and Cleaning**: Reading a CSV, identifying and dropping\n",
        "    ID/high-cardinality columns, and managing data types.\n",
        "2.  **Target Encoding**: The target column ('koi_disposition' by default) is numerically encoded.\n",
        "    Class weights are calculated to handle imbalance.\n",
        "3.  **Feature Preparation (scikit-learn)**: A ColumnTransformer is used to apply:\n",
        "    * **Numeric**: Median imputation, scaling (StandardScaler).\n",
        "    * **Categorical**: Constant imputation, One-Hot Encoding.\n",
        "    * Numeric outliers are quantile-clipped.\n",
        "4.  **Data Split**: Division into stratified training, validation, and test sets.\n",
        "5.  **PyTorch Model**: Definition and training of an MLP with Batch Normalization and Dropout.\n",
        "6.  **Monitoring**: TensorBoard is used for tracking metrics and weights.\n",
        "7.  **Saving**: The best model (based on validation loss with Early Stopping),\n",
        "    the preprocessor, and all configurations/metrics (JSON) are saved to a\n",
        "    timestamped folder, then compressed (.zip).\n",
        "\n",
        "Key Hyperparameters (configurable via environment variables):\n",
        "* CSV_PATH: Path to the input file.\n",
        "* TARGET_COLUMN: Column to predict.\n",
        "* EPOCHS, LR, BATCH_SIZE: Network training parameters.\n",
        "* HIDDEN_UNITS: MLP architecture.\n",
        "* PATIENCE: Threshold for Early Stopping.\n",
        "\n",
        "Author: Automatically detected (otherwise 'unknown_author')\n",
        "Date: Automatically generated upon execution.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import shutil\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Config / hyperparams\n",
        "\n",
        "CSV_PATH = os.environ.get(\"CSV_PATH\", \"/content/cumulative.csv\")\n",
        "TARGET_COLUMN = os.environ.get(\"TARGET_COLUMN\", \"koi_disposition\")\n",
        "OUTPUT_BASE = os.environ.get(\"OUTPUT_BASE\", \"/content/output_model\")\n",
        "AUTHOR = None  # si None -> getpass.getuser()\n",
        "SEED = int(os.environ.get(\"SEED\", 42))\n",
        "TEST_SIZE = float(os.environ.get(\"TEST_SIZE\", 0.1))\n",
        "VAL_SIZE = float(os.environ.get(\"VAL_SIZE\", 0.1))\n",
        "BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", 128))\n",
        "EPOCHS = int(os.environ.get(\"EPOCHS\", 40))\n",
        "LR = float(os.environ.get(\"LR\", 1e-3))\n",
        "HIDDEN_UNITS = [256, 128]\n",
        "PATIENCE = int(os.environ.get(\"PATIENCE\", 8))\n",
        "CLIP_LOWER_Q = 0.001\n",
        "CLIP_UPPER_Q = 0.999\n",
        "MAX_CAT_CARDINALITY = 200  # drop categorical columns with > this many unique values (likely names/ids)\n",
        "\n",
        "# ---------------------------\n",
        "# Logging\n",
        "# ---------------------------\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
        "logger = logging.getLogger(\"train_tabular_v2\")\n",
        "\n",
        "# ---------------------------\n",
        "# Reproductibilité\n",
        "# ---------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    try:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # determinism (may slow down)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "\n",
        "# Utilitaires\n",
        "def now_iso():\n",
        "    return datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n",
        "\n",
        "\n",
        "def safe_mkdir(path):\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------------------------\n",
        "# Charger CSV\n",
        "# ---------------------------\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    logger.error(f\"CSV not found: {CSV_PATH}. Place your cumulative.csv at this path in Colab.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "logger.info(f\"Loading CSV from {CSV_PATH}...\")\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "logger.info(f\"Loaded CSV with shape {df.shape}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Déterminer target\n",
        "# ---------------------------\n",
        "if TARGET_COLUMN not in df.columns:\n",
        "    TARGET_COLUMN = df.columns[-1]\n",
        "    logger.warning(f\"TARGET_COLUMN not found; using last column as target: {TARGET_COLUMN}\")\n",
        "\n",
        "\n",
        "# Retirer colonnes identifiantes et très haute cardinalité\n",
        "# heuristiques : colonnes contenant 'name', 'kepoi', 'kepler', 'id', 'rowid' souvent non-informatives\n",
        "id_like = [c for c in df.columns if any(tok in c.lower() for tok in (\"rowid\", \"kepid\", \"kepoi\", \"kepler\", \"kepoi_name\", \"kepoiid\", \"kepoi\", \"kepoi_name\")) or c.lower().endswith(\"id\")]\n",
        "# don't drop the target by mistake\n",
        "id_like = [c for c in id_like if c != TARGET_COLUMN]\n",
        "logger.info(f\"Auto-detected id-like columns to drop: {id_like}\")\n",
        "\n",
        "# Start X,y\n",
        "y_raw = df[TARGET_COLUMN].astype(str).fillna(\"NaN\")\n",
        "X = df.drop(columns=[TARGET_COLUMN])\n",
        "# drop id-like columns if present\n",
        "X = X.drop(columns=[c for c in id_like if c in X.columns])\n",
        "\n",
        "# Force coercion for columns that should be numeric but may contain strings\n",
        "# We'll detect numeric candidates by attempting to convert most entries to numeric\n",
        "candidate_numeric = []\n",
        "for c in X.columns:\n",
        "    # skip obviously categorical (object dtype) but try to detect numeric-like\n",
        "    if X[c].dtype == object:\n",
        "        non_null = X[c].dropna().head(1000)\n",
        "        # fraction of values that parse as numeric\n",
        "        parsed = pd.to_numeric(non_null, errors='coerce')\n",
        "        frac_numeric = parsed.notnull().mean() if len(parsed) > 0 else 0.0\n",
        "        if frac_numeric > 0.7:  # heuristique: >70% convertible -> numeric\n",
        "            candidate_numeric.append(c)\n",
        "\n",
        "if candidate_numeric:\n",
        "    logger.info(f\"Columns that look numeric but had object dtype (will coerce): {candidate_numeric}\")\n",
        "    for c in candidate_numeric:\n",
        "        X[c] = pd.to_numeric(X[c], errors='coerce')\n",
        "\n",
        "# Now detect numeric and categorical columns robustly\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "logger.info(f\"Detected numeric cols: {len(numeric_cols)} / categorical cols: {len(cat_cols)}\")\n",
        "\n",
        "# Drop categorical columns with extremely high cardinality (likely names/ids)\n",
        "high_card = [c for c in cat_cols if X[c].nunique(dropna=False) > MAX_CAT_CARDINALITY]\n",
        "if high_card:\n",
        "    logger.info(f\"Dropping high-cardinality categorical columns (likely names/ids): {high_card}\")\n",
        "    X = X.drop(columns=high_card)\n",
        "    cat_cols = [c for c in cat_cols if c not in high_card]\n",
        "\n",
        "# final lists\n",
        "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "logger.info(f\"Final numeric cols: {len(numeric_cols)} - Final categorical cols: {len(cat_cols)}\")\n",
        "\n",
        "# Target encoding\n",
        "label_to_idx = {lab: i for i, lab in enumerate(sorted(y_raw.unique()))}\n",
        "idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
        "y = y_raw.map(label_to_idx).values\n",
        "num_classes = len(label_to_idx)\n",
        "logger.info(f\"Target mapping: {label_to_idx} | num_classes={num_classes}\")\n",
        "\n",
        "# Clip numeric outliers (quantile-based)\n",
        "if len(numeric_cols) > 0:\n",
        "    lower = X[numeric_cols].quantile(CLIP_LOWER_Q)\n",
        "    upper = X[numeric_cols].quantile(CLIP_UPPER_Q)\n",
        "    X[numeric_cols] = X[numeric_cols].clip(lower=lower, upper=upper, axis=1)\n",
        "    logger.info(\"Applied quantile clipping to numeric columns to reduce extreme outliers.\")\n",
        "\n",
        "# Préprocesseur sklearn (impute + scale + onehot)\n",
        "num_pipe = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# OneHotEncoder compatibility\n",
        "try:\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "except TypeError:\n",
        "    # older sklearn\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"__missing__\")),\n",
        "    (\"ohe\", ohe)\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_pipe, numeric_cols),\n",
        "    (\"cat\", cat_pipe, cat_cols)\n",
        "], remainder=\"drop\", sparse_threshold=0)\n",
        "\n",
        "# Fit transformer on X (coercion already applied)\n",
        "logger.info(\"Fitting preprocessor on full dataset...\")\n",
        "X_pre = preprocessor.fit_transform(X)\n",
        "if hasattr(X_pre, \"toarray\"):\n",
        "    X_numpy = X_pre.toarray()\n",
        "else:\n",
        "    X_numpy = np.asarray(X_pre)\n",
        "logger.info(f\"Preprocessed X shape: {X_numpy.shape}\")\n",
        "\n",
        "# save schema info for configdata.json\n",
        "schema = {}\n",
        "for c in numeric_cols:\n",
        "    schema[c] = {\"dtype\": \"numeric\"}\n",
        "for c in cat_cols:\n",
        "    nunique = int(df[c].nunique(dropna=False)) if c in df.columns else None\n",
        "    sample_unique = df[c].dropna().unique().tolist()[:50] if c in df.columns else []\n",
        "    schema[c] = {\"dtype\": \"categorical\", \"nunique\": nunique, \"sample_values\": sample_unique}\n",
        "\n",
        "configdata = {\n",
        "    \"expected_columns\": list(X.columns),\n",
        "    \"numeric_columns\": numeric_cols,\n",
        "    \"categorical_columns\": cat_cols,\n",
        "    \"target_column\": TARGET_COLUMN,\n",
        "    \"label_mapping\": label_to_idx,\n",
        "    \"schema_summary\": schema,\n",
        "    \"preprocessor\": {\n",
        "        \"description\": \"ColumnTransformer with SimpleImputer+StandardScaler for numeric, SimpleImputer+OneHotEncoder for categorical. Saved in 'preprocessor.joblib'.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Split train/val/test (stratified)\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(X_numpy, y, test_size=TEST_SIZE, random_state=SEED, stratify=y)\n",
        "val_rel = VAL_SIZE / (1.0 - TEST_SIZE)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=val_rel, random_state=SEED, stratify=y_trainval)\n",
        "logger.info(f\"Train/Val/Test shapes: {X_train.shape}, {X_val.shape}, {X_test.shape}\")\n",
        "\n",
        "# Convert to torch tensors\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val_t = torch.tensor(y_val, dtype=torch.long)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "val_ds = TensorDataset(X_val_t, y_val_t)\n",
        "test_ds = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Définir modèle PyTorch MLP\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_layers = HIDDEN_UNITS\n",
        "output_dim = num_classes\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev = h\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP(input_dim, hidden_layers, output_dim).to(device)\n",
        "\n",
        "# Loss (with optional class weights) and optimizer\n",
        "# compute class weights inversely proportional to frequency\n",
        "class_counts = np.bincount(y_trainval)\n",
        "inv_freq = 1.0 / (class_counts + 1e-12)\n",
        "weights = inv_freq / inv_freq.sum() * len(class_counts)  # normalized-ish\n",
        "weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# Préparer dossier de sortie et TensorBoard\n",
        "timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "output_dir = f\"{OUTPUT_BASE}_{timestamp}\"\n",
        "safe_mkdir(output_dir)\n",
        "writer = SummaryWriter(log_dir=os.path.join(output_dir, \"tb_logs\"))\n",
        "\n",
        "# Training loop with early stopping + TB logging\n",
        "best_val_loss = float(\"inf\")\n",
        "best_epoch = -1\n",
        "epochs_no_improve = 0\n",
        "history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_accum = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss_accum += loss.item() * xb.size(0)\n",
        "            preds = out.argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += xb.size(0)\n",
        "    return loss_accum / total, correct / total\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * xb.size(0)\n",
        "        preds = out.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += xb.size(0)\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = correct / total\n",
        "    val_loss, val_acc = evaluate(val_loader)\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"val_loss\"].append(val_loss)\n",
        "    history[\"train_acc\"].append(train_acc)\n",
        "    history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "    # TensorBoard logs\n",
        "    writer.add_scalar(\"loss/train\", train_loss, epoch)\n",
        "    writer.add_scalar(\"loss/val\", val_loss, epoch)\n",
        "    writer.add_scalar(\"acc/train\", train_acc, epoch)\n",
        "    writer.add_scalar(\"acc/val\", val_acc, epoch)\n",
        "\n",
        "    # log histograms of weights (every 5 epochs)\n",
        "    if epoch % 5 == 0:\n",
        "        for name, param in model.named_parameters():\n",
        "            writer.add_histogram(name, param.detach().cpu().numpy(), epoch)\n",
        "\n",
        "    logger.info(f\"Epoch {epoch}/{EPOCHS} | train_loss={train_loss:.6f} val_loss={val_loss:.6f} train_acc={train_acc:.4f} val_acc={val_acc:.4f}\")\n",
        "\n",
        "    # early stopping\n",
        "    if val_loss < best_val_loss - 1e-6:\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "        epochs_no_improve = 0\n",
        "        # Save best model state temporarily\n",
        "        best_state = model.state_dict()\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            logger.info(f\"Early stopping at epoch {epoch} (no improvement for {PATIENCE} epochs)\")\n",
        "            break\n",
        "\n",
        "# Load best state\n",
        "if 'best_state' in locals():\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "# Evaluate on test\n",
        "test_loss, test_acc = evaluate(test_loader)\n",
        "logger.info(f\"Test loss={test_loss:.6f} test_acc={test_acc:.4f}\")\n",
        "\n",
        "# Sauvegardes : modèle, preprocessor, config.json, configdata.json\n",
        "# model: save both state_dict and a full checkpoint\n",
        "model_path = os.path.join(output_dir, \"model.pth\")\n",
        "torch.save(model.state_dict(), model_path)\n",
        "# full checkpoint\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoint.pt\")\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'config': {\n",
        "        'input_dim': input_dim,\n",
        "        'hidden_layers': hidden_layers,\n",
        "        'output_dim': output_dim,\n",
        "        'num_classes': num_classes,\n",
        "        'preprocessor_file': 'preprocessor.joblib'\n",
        "    }\n",
        "}, checkpoint_path)\n",
        "\n",
        "# preprocessor\n",
        "preproc_path = os.path.join(output_dir, \"preprocessor.joblib\")\n",
        "joblib.dump(preprocessor, preproc_path)\n",
        "\n",
        "# config.json\n",
        "if AUTHOR is None:\n",
        "    try:\n",
        "        AUTHOR = getpass.getuser()\n",
        "    except Exception:\n",
        "        AUTHOR = \"unknown_author\"\n",
        "\n",
        "config = {\n",
        "    \"author\": str(AUTHOR),\n",
        "    \"created_at_utc\": now_iso(),\n",
        "    \"model_type\": \"PyTorch_MLP_tabular\",\n",
        "    \"model_file\": os.path.basename(model_path),\n",
        "    \"checkpoint_file\": os.path.basename(checkpoint_path),\n",
        "    \"preprocessor_file\": os.path.basename(preproc_path),\n",
        "    \"input_dim\": input_dim,\n",
        "    \"hidden_layers\": HIDDEN_UNITS,\n",
        "    \"output_dim\": output_dim,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"hyperparameters\": {\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs_requested\": EPOCHS,\n",
        "        \"learning_rate\": LR,\n",
        "        \"patience\": PATIENCE\n",
        "    },\n",
        "    \"data_split\": {\n",
        "        \"train_size\": int(len(X_train)),\n",
        "        \"val_size\": int(len(X_val)),\n",
        "        \"test_size\": int(len(X_test))\n",
        "    },\n",
        "    \"target_mapping\": label_to_idx,\n",
        "    \"final_metrics\": {\n",
        "        \"best_epoch\": int(best_epoch),\n",
        "        \"test_loss\": float(test_loss),\n",
        "        \"test_accuracy\": float(test_acc)\n",
        "    },\n",
        "    \"notes\": \"Preprocessor is a ColumnTransformer (num imputer+scaler, cat imputer+onehot). High-cardinality cat columns were dropped automatically.\"\n",
        "}\n",
        "\n",
        "with open(os.path.join(output_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# configdata.json\n",
        "with open(os.path.join(output_dir, \"configdata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(configdata, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "# Save training history\n",
        "with open(os.path.join(output_dir, \"train_history.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "\n",
        "# Zip the folder\n",
        "zipname = f\"{output_dir}.zip\"\n",
        "try:\n",
        "    shutil.make_archive(output_dir, 'zip', output_dir)\n",
        "    logger.info(f\"All outputs written to: {output_dir}\")\n",
        "    logger.info(f\"Zipped artifact produced: {zipname}\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Failed to create zip archive: {e}\")\n",
        "\n",
        "print(\"\\n--- FIN ---\")\n",
        "print(f\"Outputs in: {output_dir}\")\n",
        "print(\"Files: model.pth, checkpoint.pt, preprocessor.joblib, config.json, configdata.json, train_history.json, tb_logs/\")\n",
        "print(\"To inspect TensorBoard logs (in Colab), run:\\n  %load_ext tensorboard\\n  %tensorboard --logdir {output_dir}/tb_logs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F-zlsnkVMoU",
        "outputId": "030d071f-aa64-4fd5-be68-32d3e26ce8b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['koi_teq_err1' 'koi_teq_err2']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3879327266.py:307: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  timestamp = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- FIN ---\n",
            "Outputs in: /content/output_model_20251004T134145Z\n",
            "Files: model.pth, checkpoint.pt, preprocessor.joblib, config.json, configdata.json, train_history.json, tb_logs/\n",
            "To inspect TensorBoard logs (in Colab), run:\n",
            "  %load_ext tensorboard\n",
            "  %tensorboard --logdir {output_dir}/tb_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3879327266.py:94: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import json\n",
        "import io\n",
        "\n",
        "# Config\n",
        "model_dir = Path(\"output_model_20251004T134145Z\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load configdata to get column information\n",
        "try:\n",
        "    with open(model_dir / \"configdata.json\", \"r\") as f:\n",
        "        configdata = json.load(f)\n",
        "    expected_columns = configdata.get(\"expected_columns\", [])\n",
        "    # Explicitly get the lists of numeric and categorical columns from configdata\n",
        "    numeric_cols_train = configdata.get(\"numeric_columns\", [])\n",
        "    cat_cols_train = configdata.get(\"categorical_columns\", [])\n",
        "    label_mapping = configdata.get(\"label_mapping\", {})\n",
        "    idx_to_label = {v: k for k, v in label_mapping.items()}\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: configdata.json not found in {model_dir}. Cannot proceed without column information.\")\n",
        "    exit()\n",
        "\n",
        "# 🔹 Données de test,  Test data\n",
        "data = \"\"\"rowid,kepid,kepoi_name,kepler_name,koi_pdisposition,koi_score,koi_fpflag_nt,koi_fpflag_ss,koi_fpflag_co,koi_fpflag_ec,koi_period,koi_period_err1,koi_period_err2,koi_time0bk,koi_time0bk_err1,koi_time0bk_err2,koi_impact,koi_impact_err1,koi_impact_err2,koi_duration,koi_duration_err1,koi_duration_err2,koi_depth,koi_depth_err1,koi_depth_err2,koi_prad,koi_prad_err1,koi_prad_err2,koi_teq,koi_teq_err1,koi_teq_err2,koi_insol,koi_insol_err1,koi_insol_err2,koi_model_snr,koi_tce_plnt_num,koi_tce_delivname,koi_steff,koi_steff_err1,koi_steff_err2,koi_slogg,koi_slogg_err1,koi_slogg_err2,koi_srad,koi_srad_err1,koi_srad_err2,ra,dec,koi_kepmag\n",
        "1,10797460,K00752.01,Kepler-227 b,CANDIDATE,1.0000,0,0,0,0,9.488035570,2.7750000e-05,-2.7750000e-05,170.5387500,2.160000e-03,-2.160000e-03,0.1460,0.3180,-0.1460,2.95750,0.08190,-0.08190,6.1580e+02,1.950e+01,-1.950e+01,2.26,2.600e-01,-1.500e-01,793.0,,,93.59,29.45,-16.65,35.80,1,q1_q17_dr25_tce,5455.00,81.00,-81.00,4.467,0.064,-0.096,0.9270,0.1050,-0.0610,291.934230,48.141651,15.347\n",
        "2,10797460,K00752.02,Kepler-227 c,CANDIDATE,0.9690,0,0,0,0,54.418382700,2.4790000e-04,-2.4790000e-04,162.5138400,3.520000e-03,-3.520000e-03,0.5860,0.0590,-0.4430,4.50700,0.11600,-0.11600,8.7480e+02,3.550e+01,-3.550e+01,2.83,3.200e-01,-1.900e-01,443.0,,,9.11,2.87,-1.62,25.80,2,q1_q17_dr25_tce,5455.00,81.00,-81.00,4.467,0.064,-0.096,0.9270,0.1050,-0.0610,291.934230,48.141651,15.347\n",
        "3,10811496,K00753.01,FALSE POSITIVE,0.0000,0,1,0,0,19.899139950,1.4940000e-05,-1.4940000e-05,175.8502520,5.810000e-04,-5.810000e-04,0.9690,5.1260,-0.0770,1.78220,0.03410,-0.03410,1.0829e+04,1.710e+02,-1.710e+02,14.60,3.920e+00,-1.310e+00,638.0,,,39.30,31.04,-10.49,76.30,1,q1_q17_dr25_tce,5853.00,158.00,-176.00,4.544,0.044,-0.176,0.8680,0.2330,-0.0780,297.004820,48.134129,15.436\n",
        "4,10848459,K00754.01,FALSE POSITIVE,0.0000,0,1,0,0,1.736952453,2.6300000e-07,-2.6300000e-07,170.3075650,1.150000e-04,-1.150000e-04,0.0000,0.0000,0.0000,2.63120,0.00530,-0.00530,1.3900e+02,1.620e+01,-1.620e+01,1.49,8.400e-01,-3.000e-01,1395.0,,,891.96,668.95,-230.23,13.90,1,q1_q17_dr25_tce,5805.00,71.00,-71.00,4.564,0.053,-0.168,0.7910,0.2010,-0.0670,285.534610,48.285210,15.597\n",
        ",10147276,K07987.01,FALSE POSITIVE,0.0210,0,0,1,0,0.681401611,2.4340000e-06,-2.4340000e-06,132.1817500,2.850000e-03,-2.850000e-03,0.1470,0.3090,-0.1470,0.86500,0.16200,-0.16200,1.0360e+02,1.470e+01,-1.470e+01,1.07,3.600e-01,-1.100e-01,2218.0,,,5713.41,5675.74,-1836.94,12.30,1,q1_q17_dr25_tce,6173.00,193.00,-236.00,4.447,0.056,-0.224,1.0410,0.3410,-0.1140,294.164890,47.176281,15.385\n",
        "6,10156110,K07989.01,FALSE POSITIVE,0.0000,0,0,1,1,4.856034820,6.3560000e-05,-6.3560000e-05,135.9933000,1.080000e-02,-1.080000e-02,0.1340,0.3230,-0.1340,3.07800,0.28300,-0.28300,7.6700e+01,1.080e+01,-1.080e+01,1.05,3.600e-01,-1.200e-01,1266.0,,,607.42,600.39,-194.33,8.20,1,q1_q17_dr25_tce,6469.00,158.00,-225.00,4.385,0.054,-0.216,1.1930,0.4100,-0.1370,297.009770,47.121021,14.826\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Read the string data into a DataFrame\n",
        "df = pd.read_csv(io.StringIO(data))\n",
        "\n",
        "# --- IMPORTANT: Remove the target column 'koi_disposition' before prediction ---\n",
        "if 'koi_disposition' in df.columns:\n",
        "    df_with_target = df.copy() # Keep a copy with target for comparison if needed\n",
        "    df = df.drop(columns=['koi_disposition'])\n",
        "\n",
        "# Remove columns that were dropped during training (id-like and high cardinality)\n",
        "# These were identified and dropped in the training script\n",
        "id_like_cols = [\"rowid\", \"kepid\", \"kepoi_name\", \"kepler_name\"] # Add kepler_name\n",
        "df = df.drop(columns=[c for c in id_like_cols if c in df.columns])\n",
        "\n",
        "# Ensure the order of columns matches the training data's expected columns\n",
        "# Filter expected_columns to exclude those we just dropped (and the target if it was in expected_columns)\n",
        "# Note: expected_columns from configdata.json should NOT contain the target\n",
        "filtered_expected_columns = [c for c in expected_columns if c in df.columns]\n",
        "df = df[filtered_expected_columns]\n",
        "\n",
        "# Force coercion for columns identified as numeric during training\n",
        "for c in numeric_cols_train:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "# Handle potential missing columns in the test data compared to training data\n",
        "# Add missing columns with NaN values and ensure they are of appropriate type\n",
        "missing_cols = set(expected_columns) - set(df.columns)\n",
        "for c in missing_cols:\n",
        "    df[c] = np.nan # Add as NaN initially\n",
        "    print(f\"Warning: Added missing column '{c}' to test data.\")\n",
        "\n",
        "# Ensure the order of columns is the same as during training\n",
        "df = df[expected_columns]\n",
        "\n",
        "# Define clipping bounds (should match those used during training)\n",
        "CLIP_LOWER_Q = 0.001\n",
        "CLIP_UPPER_Q = 0.999\n",
        "\n",
        "# Apply clipping only to columns that were numeric during training AND are currently numeric in the test DataFrame\n",
        "# Explicitly filter for numeric dtypes in the current dataframe slice\n",
        "numeric_cols_for_clipping = [c for c in numeric_cols_train if c in df.columns and pd.api.types.is_numeric_dtype(df[c])]\n",
        "\n",
        "if len(numeric_cols_for_clipping) > 0:\n",
        "    # Calculate quartiles on the test data subset for the relevant numeric columns\n",
        "    # A more robust production system would save and load these bounds from training.\n",
        "    lower = df[numeric_cols_for_clipping].quantile(CLIP_LOWER_Q)\n",
        "    upper = df[numeric_cols_for_clipping].quantile(CLIP_UPPER_Q)\n",
        "    # Apply clipping only to the numeric subset\n",
        "    df[numeric_cols_for_clipping] = df[numeric_cols_for_clipping].clip(lower=lower, upper=upper, axis=1)\n",
        "    print(\"Applied quantile clipping to numeric columns in test data.\")\n",
        "else:\n",
        "    print(\"No numeric columns found for clipping in test data.\")\n",
        "\n",
        "# 🔹 Charger le scaler\n",
        "scaler = joblib.load(model_dir / \"preprocessor.joblib\")\n",
        "\n",
        "# Apply the preprocessor to the DataFrame\n",
        "X_test = scaler.transform(df)\n",
        "\n",
        "\n",
        "# Définition du modèle MLP (exactement comme pour l'entraînement), MLP MODEL DEFINITION\n",
        "# Get input_dim, hidden_layers, and num_classes from the saved config\n",
        "try:\n",
        "    with open(model_dir / \"config.json\", \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    input_dim = config[\"input_dim\"]\n",
        "    hidden_layers = config[\"hidden_layers\"]\n",
        "    num_classes = config[\"num_classes\"]\n",
        "    # label_mapping and idx_to_label already loaded from configdata.json\n",
        "except FileNotFoundError:\n",
        "     print(f\"Error: config.json not found in {model_dir}. Cannot proceed.\")\n",
        "     exit()\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for h in hidden_layers:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            prev = h\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 🔹 Charger le modèle\n",
        "model = MLP(input_dim, hidden_layers, num_classes).to(device)\n",
        "model.load_state_dict(torch.load(model_dir / \"model.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# 🔹 Prédiction\n",
        "with torch.no_grad():\n",
        "    X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    outputs = model(X_tensor)\n",
        "    probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "    predictions_idx = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "    predictions_label = [idx_to_label[idx] for idx in predictions_idx]\n",
        "\n",
        "\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predictions (index):\", predictions_idx)\n",
        "print(\"Predictions (label):\", predictions_label)\n",
        "\n",
        "# Print the original data with predictions for comparison\n",
        "# Use the original df_with_target if it exists, otherwise use df\n",
        "df_to_display = df_with_target if 'df_with_target' in locals() else df\n",
        "df_to_display['predicted_disposition'] = predictions_label\n",
        "print(\"\\nOriginal Data with Predictions:\")\n",
        "# Include koi_disposition from the original data for comparison if available\n",
        "display_cols = ['koi_disposition', 'predicted_disposition', 'koi_pdisposition'] + [c for c in filtered_expected_columns if c not in ['koi_pdisposition']]\n",
        "display(df_to_display[display_cols])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "K15dbFPvZU00",
        "outputId": "fcb226fa-bd38-4e7a-e4ff-1561f4f587bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied quantile clipping to numeric columns in test data.\n",
            "Probabilities: [[7.7814929e-02 9.2212814e-01 5.6918034e-05]\n",
            " [6.0487472e-02 9.3947583e-01 3.6704889e-05]\n",
            " [0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
            " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
            "Predictions (index): [1 1 2 0 0 0]\n",
            "Predictions (label): ['CONFIRMED', 'CONFIRMED', 'FALSE POSITIVE', 'CANDIDATE', 'CANDIDATE', 'CANDIDATE']\n",
            "\n",
            "Original Data with Predictions:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['koi_teq_err1' 'koi_teq_err2']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  koi_disposition predicted_disposition koi_pdisposition  koi_score  \\\n",
              "0       CONFIRMED             CONFIRMED        CANDIDATE      1.000   \n",
              "1       CONFIRMED             CONFIRMED        CANDIDATE      0.969   \n",
              "2  FALSE POSITIVE        FALSE POSITIVE   FALSE POSITIVE      0.000   \n",
              "3  FALSE POSITIVE             CANDIDATE   FALSE POSITIVE      0.000   \n",
              "4          0.0210             CANDIDATE                0      0.000   \n",
              "5          0.0000             CANDIDATE                0      0.000   \n",
              "\n",
              "   koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
              "0              0              0       0.000000       0.000000    9.488036   \n",
              "1              0              0       0.000000       0.000000   54.418383   \n",
              "2              0              1       0.000000       0.000000   19.899140   \n",
              "3              0              1       0.000000       0.000000    1.736952   \n",
              "4              1              0       0.681402       0.000002   -0.000002   \n",
              "5              1              1       4.856035       0.000064   -0.000064   \n",
              "\n",
              "   koi_period_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
              "0     2.775000e-05  ...         -81.000      4.467           0.064   \n",
              "1     2.479000e-04  ...         -81.000      4.467           0.064   \n",
              "2     1.494000e-05  ...        -176.000      4.544           0.044   \n",
              "3     2.630000e-07  ...         -71.000      4.564           0.053   \n",
              "4     1.321817e+02  ...           0.056     -0.224           1.041   \n",
              "5     1.359933e+02  ...           0.054     -0.216           1.193   \n",
              "\n",
              "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
              "0          -0.096     0.927        0.10500      -0.061000  291.93423   \n",
              "1          -0.096     0.927        0.10500      -0.061000  291.93423   \n",
              "2          -0.176     0.868        0.23300      -0.078000  297.00482   \n",
              "3          -0.168     0.791        0.20100      -0.067000  285.53461   \n",
              "4           0.341    -0.114      294.16489      47.176281   15.38500   \n",
              "5           0.410    -0.137      297.00977      47.121021   14.82600   \n",
              "\n",
              "         dec  koi_kepmag  \n",
              "0  48.141651      15.347  \n",
              "1  48.141651      15.347  \n",
              "2  48.134129      15.436  \n",
              "3  48.285210      15.597  \n",
              "4        NaN         NaN  \n",
              "5        NaN         NaN  \n",
              "\n",
              "[6 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2cd5053-5d41-42d5-bbac-bf3858fc3c1a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>koi_disposition</th>\n",
              "      <th>predicted_disposition</th>\n",
              "      <th>koi_pdisposition</th>\n",
              "      <th>koi_score</th>\n",
              "      <th>koi_fpflag_nt</th>\n",
              "      <th>koi_fpflag_ss</th>\n",
              "      <th>koi_fpflag_co</th>\n",
              "      <th>koi_fpflag_ec</th>\n",
              "      <th>koi_period</th>\n",
              "      <th>koi_period_err1</th>\n",
              "      <th>...</th>\n",
              "      <th>koi_steff_err2</th>\n",
              "      <th>koi_slogg</th>\n",
              "      <th>koi_slogg_err1</th>\n",
              "      <th>koi_slogg_err2</th>\n",
              "      <th>koi_srad</th>\n",
              "      <th>koi_srad_err1</th>\n",
              "      <th>koi_srad_err2</th>\n",
              "      <th>ra</th>\n",
              "      <th>dec</th>\n",
              "      <th>koi_kepmag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.488036</td>\n",
              "      <td>2.775000e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>-81.000</td>\n",
              "      <td>4.467</td>\n",
              "      <td>0.064</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.10500</td>\n",
              "      <td>-0.061000</td>\n",
              "      <td>291.93423</td>\n",
              "      <td>48.141651</td>\n",
              "      <td>15.347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>CONFIRMED</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>0.969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.418383</td>\n",
              "      <td>2.479000e-04</td>\n",
              "      <td>...</td>\n",
              "      <td>-81.000</td>\n",
              "      <td>4.467</td>\n",
              "      <td>0.064</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.10500</td>\n",
              "      <td>-0.061000</td>\n",
              "      <td>291.93423</td>\n",
              "      <td>48.141651</td>\n",
              "      <td>15.347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.899140</td>\n",
              "      <td>1.494000e-05</td>\n",
              "      <td>...</td>\n",
              "      <td>-176.000</td>\n",
              "      <td>4.544</td>\n",
              "      <td>0.044</td>\n",
              "      <td>-0.176</td>\n",
              "      <td>0.868</td>\n",
              "      <td>0.23300</td>\n",
              "      <td>-0.078000</td>\n",
              "      <td>297.00482</td>\n",
              "      <td>48.134129</td>\n",
              "      <td>15.436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>FALSE POSITIVE</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.736952</td>\n",
              "      <td>2.630000e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>-71.000</td>\n",
              "      <td>4.564</td>\n",
              "      <td>0.053</td>\n",
              "      <td>-0.168</td>\n",
              "      <td>0.791</td>\n",
              "      <td>0.20100</td>\n",
              "      <td>-0.067000</td>\n",
              "      <td>285.53461</td>\n",
              "      <td>48.285210</td>\n",
              "      <td>15.597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0210</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.681402</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>1.321817e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056</td>\n",
              "      <td>-0.224</td>\n",
              "      <td>1.041</td>\n",
              "      <td>0.341</td>\n",
              "      <td>-0.114</td>\n",
              "      <td>294.16489</td>\n",
              "      <td>47.176281</td>\n",
              "      <td>15.38500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>CANDIDATE</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.856035</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>1.359933e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054</td>\n",
              "      <td>-0.216</td>\n",
              "      <td>1.193</td>\n",
              "      <td>0.410</td>\n",
              "      <td>-0.137</td>\n",
              "      <td>297.00977</td>\n",
              "      <td>47.121021</td>\n",
              "      <td>14.82600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 47 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2cd5053-5d41-42d5-bbac-bf3858fc3c1a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2cd5053-5d41-42d5-bbac-bf3858fc3c1a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2cd5053-5d41-42d5-bbac-bf3858fc3c1a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1e85963d-d61a-4ab0-ace3-ccc35e31df6f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e85963d-d61a-4ab0-ace3-ccc35e31df6f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1e85963d-d61a-4ab0-ace3-ccc35e31df6f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}